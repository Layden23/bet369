{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning:\n",
      "\n",
      "The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric     RF   LR  XGB\n",
      "Accuracy  0.62 0.69 0.67\n",
      "Kappa     0.24 0.38 0.35\n",
      "Precision 0.71 0.73 0.71\n",
      "Recall    0.58 0.65 0.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd,numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score,cohen_kappa_score,confusion_matrix,recall_score,precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import time, random\n",
    "import xgboost as xgb\n",
    "#Set Seed\n",
    "random.seed(69)\n",
    "#Read dataset\n",
    "train = pd.read_csv(\"/Users/jojoel/Google Drive/Github/bet369/Datasets/train2.csv\", header = 0)\n",
    "#Remove columns with lots of missing values\n",
    "del train[\"BettingCuoteHT\"]\n",
    "del train[\"BettingCuoteFT\"]\n",
    "del train[\"HostGoalsFT\"]\n",
    "del train[\"GuestGoalsFT\"]\n",
    "#Filter matches with HT\n",
    "train = train[train['Status']== \"HT\"]\n",
    "train = train.drop_duplicates(subset = \"MatchID\")\n",
    "#Remove last row wich are the features again\n",
    "train = train.iloc[:-1]\n",
    "#Remove matches with no posession\n",
    "train = train.loc[(train['HostPossessionFT'] != \"0\") & (train['GuestPossessionFT'] != \"0\")]\n",
    "# Indicies of each class' observations\n",
    "i_class0 = np.where(train[\"Goal\"] == \"0\")[0]\n",
    "i_class1 = np.where(train[\"Goal\"] == \"1\")[0]\n",
    "\n",
    "#Get size of the underrepresented class\n",
    "n_class0 = len(i_class0)\n",
    "\n",
    "#Create new train with classes equally represented\n",
    "i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "train = train.iloc[i_class0,:].append(train.iloc[i_class1_downsampled])\n",
    "#Feature-engineering\n",
    "X = train.iloc[:,12:32]\n",
    "stand = MinMaxScaler().fit(X)\n",
    "X = pd.DataFrame(stand.transform(X))\n",
    "pca = PCA(0.99)\n",
    "pca.fit(X)\n",
    "pcX = pca.transform(X)\n",
    "y = train[\"Goal\"]\n",
    "#Transform variables to numeric\n",
    "for i in X.columns:\n",
    "    X[i] = pd.to_numeric(X[i])\n",
    "y = pd.to_numeric(y)\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pcX,y,train_size = 0.7)\n",
    "#Models\n",
    "rf = RandomForestClassifier(n_estimators = 200)\n",
    "rf.fit(X_train, y_train)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "xgb = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "xgb.fit(X_train,y_train)\n",
    "#Predictions\n",
    "rfpreds = rf.predict(X_test)\n",
    "lrpreds = lr.predict(X_test)\n",
    "xgbpreds = xgb.predict(X_test)\n",
    "#Probabilities\n",
    "rfprobs = rf.predict_proba(X_test)[:,1]\n",
    "lrprobs = lr.predict_proba(X_test)[:,1]\n",
    "xgbprobs = xgb.predict_proba(X_test)[:,1]\n",
    "#Results\n",
    "print(\"Metric   \",\" RF \",\" LR \",\"XGB\")\n",
    "print(\"Accuracy \", round(accuracy_score(rfpreds,y_test),2), round(accuracy_score(lrpreds,y_test),2), \n",
    "      round(accuracy_score(xgbpreds,y_test),2))\n",
    "print(\"Kappa    \",round(cohen_kappa_score(rfpreds,y_test),2),round(cohen_kappa_score(lrpreds,y_test),2),\n",
    "      round(cohen_kappa_score(xgbpreds,y_test),2))\n",
    "print(\"Precision\",round(precision_score(rfpreds,y_test),2),round(precision_score(lrpreds,y_test),2),\n",
    "      round(precision_score(xgbpreds,y_test),2))\n",
    "print(\"Recall   \", round(recall_score(rfpreds,y_test),2),round(recall_score(lrpreds,y_test),2),\n",
    "      round(recall_score(xgbpreds,y_test),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
